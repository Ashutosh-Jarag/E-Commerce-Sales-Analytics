{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae51ea5",
   "metadata": {},
   "source": [
    "# Understading the sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c14bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8512f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bffa3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "customers_dataset = pd.read_csv(\"data/olist_customers_dataset.csv\")\n",
    "print(customers_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f44a7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "geolocation_dataset = pd.read_csv(\"data/olist_geolocation_dataset.csv\")\n",
    "print(customers_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32c6005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "order_item_dataset = pd.read_csv(\"data/olist_order_items_dataset.csv\")\n",
    "print(customers_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e34c6f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>payment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b81ef226f3fe1789b1e8b2acac839d17</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>8</td>\n",
       "      <td>99.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9810da82917af2d9aefd1278f1dcfa0</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>24.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>1</td>\n",
       "      <td>65.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba78997921bbcdc1373bb41e913ab953</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>8</td>\n",
       "      <td>107.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42fdf880ba16b47b59251dd489d4441a</td>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>2</td>\n",
       "      <td>128.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id  payment_sequential payment_type  \\\n",
       "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
       "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
       "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
       "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
       "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
       "\n",
       "   payment_installments  payment_value  \n",
       "0                     8          99.33  \n",
       "1                     1          24.39  \n",
       "2                     1          65.71  \n",
       "3                     8         107.78  \n",
       "4                     2         128.45  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_payments_dataset = pd.read_csv(\"data/olist_order_payments_dataset.csv\")\n",
    "order_payments_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b1cd81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ParabÃ©ns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN  2018-01-18 00:00:00   \n",
       "1                                                NaN  2018-03-10 00:00:00   \n",
       "2                                                NaN  2018-02-17 00:00:00   \n",
       "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4  ParabÃ©ns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_reviews_dataset = pd.read_csv(\"data/olist_order_reviews_dataset.csv\")\n",
    "order_reviews_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10638c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_dataset = pd.read_csv(\"data/olist_orders_dataset.csv\")\n",
    "orders_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d66168e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         product_id  product_category_name  \\\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
      "\n",
      "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
      "0                 40.0                       287.0                 1.0   \n",
      "1                 44.0                       276.0                 1.0   \n",
      "2                 46.0                       250.0                 1.0   \n",
      "3                 27.0                       261.0                 1.0   \n",
      "4                 37.0                       402.0                 4.0   \n",
      "\n",
      "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
      "0             225.0               16.0               10.0              14.0  \n",
      "1            1000.0               30.0               18.0              20.0  \n",
      "2             154.0               18.0                9.0              15.0  \n",
      "3             371.0               26.0                4.0              26.0  \n",
      "4             625.0               20.0               17.0              13.0  \n"
     ]
    }
   ],
   "source": [
    "products_dataset = pd.read_csv(\"data/olist_products_dataset.csv\")\n",
    "print(products_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91429470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          seller_id  seller_zip_code_prefix  \\\n",
      "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
      "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
      "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
      "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
      "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
      "\n",
      "         seller_city seller_state  \n",
      "0           campinas           SP  \n",
      "1         mogi guacu           SP  \n",
      "2     rio de janeiro           RJ  \n",
      "3          sao paulo           SP  \n",
      "4  braganca paulista           SP  \n"
     ]
    }
   ],
   "source": [
    "sellers_dataset = pd.read_csv(\"data/olist_sellers_dataset.csv\")\n",
    "print(sellers_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfa6bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            product_category_name product_category_name_english\n",
      "0                    beleza_saude                 health_beauty\n",
      "1          informatica_acessorios         computers_accessories\n",
      "2                      automotivo                          auto\n",
      "3                 cama_mesa_banho                bed_bath_table\n",
      "4                moveis_decoracao               furniture_decor\n",
      "..                            ...                           ...\n",
      "66                         flores                       flowers\n",
      "67             artes_e_artesanato         arts_and_craftmanship\n",
      "68                fraldas_higiene           diapers_and_hygiene\n",
      "69  fashion_roupa_infanto_juvenil     fashion_childrens_clothes\n",
      "70             seguros_e_servicos         security_and_services\n",
      "\n",
      "[71 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "translation = pd.read_csv(\"data/product_category_name_translation.csv\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c6a8b",
   "metadata": {},
   "source": [
    "Query 1: Total Revenue by Year and Quarter\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 1: Total Revenue by Year and Quarter\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create temporary views so we can use SQL\n",
    "fact_sales.createOrReplaceTempView(\"fact_sales\")\n",
    "dim_date.createOrReplaceTempView(\"dim_date\")\n",
    "dim_customer.createOrReplaceTempView(\"dim_customer\")\n",
    "dim_product.createOrReplaceTempView(\"dim_product\")\n",
    "dim_seller.createOrReplaceTempView(\"dim_seller\")\n",
    "\n",
    "# SQL Query\n",
    "query1 = \"\"\"\n",
    "SELECT \n",
    "    d.year,\n",
    "    d.quarter,\n",
    "    COUNT(DISTINCT f.order_id) as total_orders,\n",
    "    COUNT(f.sale_key) as total_items_sold,\n",
    "    ROUND(SUM(f.total_amount), 2) as total_revenue,\n",
    "    ROUND(AVG(f.total_amount), 2) as avg_order_value\n",
    "FROM fact_sales f\n",
    "JOIN dim_date d ON f.date_key = d.date_key\n",
    "GROUP BY d.year, d.quarter\n",
    "ORDER BY d.year, d.quarter\n",
    "\"\"\"\n",
    "\n",
    "result1 = spark.sql(query1)\n",
    "display(result1)\n",
    "Business Question: \"How is our revenue trending over time?\"\n",
    "\n",
    "Query 2: Top 10 Best-Selling Product Categories\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 2: Top 10 Best-Selling Product Categories\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT \n",
    "    p.product_category_name as category,\n",
    "    COUNT(f.sale_key) as items_sold,\n",
    "    ROUND(SUM(f.total_amount), 2) as total_revenue,\n",
    "    ROUND(AVG(f.review_score), 2) as avg_rating\n",
    "FROM fact_sales f\n",
    "JOIN dim_product p ON f.product_key = p.product_key\n",
    "WHERE p.product_category_name != 'Unknown'\n",
    "GROUP BY p.product_category_name\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result2 = spark.sql(query2)\n",
    "display(result2)\n",
    "Business Question: \"Which product categories make us the most money?\"\n",
    "\n",
    "Query 3: Customer Segmentation Analysis\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 3: Revenue by Customer Segment\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    c.customer_segment,\n",
    "    COUNT(DISTINCT c.customer_key) as total_customers,\n",
    "    COUNT(f.sale_key) as total_purchases,\n",
    "    ROUND(SUM(f.total_amount), 2) as total_revenue,\n",
    "    ROUND(AVG(f.total_amount), 2) as avg_purchase_value,\n",
    "    ROUND(SUM(f.total_amount) / COUNT(DISTINCT c.customer_key), 2) as revenue_per_customer\n",
    "FROM fact_sales f\n",
    "JOIN dim_customer c ON f.customer_key = c.customer_key\n",
    "GROUP BY c.customer_segment\n",
    "ORDER BY total_revenue DESC\n",
    "\"\"\"\n",
    "\n",
    "result3 = spark.sql(query3)\n",
    "display(result3)\n",
    "Business Question: \"Which customer segments are most valuable?\"\n",
    "\n",
    "Query 4: Top 10 States by Revenue\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 4: Top 10 States by Revenue\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query4 = \"\"\"\n",
    "SELECT \n",
    "    c.customer_state as state,\n",
    "    COUNT(DISTINCT f.order_id) as total_orders,\n",
    "    ROUND(SUM(f.total_amount), 2) as total_revenue,\n",
    "    ROUND(AVG(f.review_score), 2) as avg_customer_satisfaction\n",
    "FROM fact_sales f\n",
    "JOIN dim_customer c ON f.customer_key = c.customer_key\n",
    "GROUP BY c.customer_state\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result4 = spark.sql(query4)\n",
    "display(result4)\n",
    "Business Question: \"Which states generate the most revenue?\"\n",
    "\n",
    "Query 5: Sales Performance by Day of Week\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 5: Sales by Day of Week\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query5 = \"\"\"\n",
    "SELECT \n",
    "    d.day_name,\n",
    "    d.is_weekend,\n",
    "    COUNT(f.sale_key) as total_sales,\n",
    "    ROUND(SUM(f.total_amount), 2) as revenue,\n",
    "    ROUND(AVG(f.total_amount), 2) as avg_order_value\n",
    "FROM fact_sales f\n",
    "JOIN dim_date d ON f.date_key = d.date_key\n",
    "GROUP BY d.day_name, d.is_weekend, d.day_of_week\n",
    "ORDER BY d.day_of_week\n",
    "\"\"\"\n",
    "\n",
    "result5 = spark.sql(query5)\n",
    "display(result5)\n",
    "Business Question: \"Do we sell more on weekends or weekdays?\"\n",
    "\n",
    "Query 6: Top 10 Sellers by Performance\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 6: Top 10 Sellers by Revenue\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query6 = \"\"\"\n",
    "SELECT \n",
    "    s.seller_state,\n",
    "    s.seller_city,\n",
    "    COUNT(f.sale_key) as items_sold,\n",
    "    ROUND(SUM(f.total_amount), 2) as total_revenue,\n",
    "    ROUND(AVG(f.review_score), 2) as avg_seller_rating\n",
    "FROM fact_sales f\n",
    "JOIN dim_seller s ON f.seller_key = s.seller_key\n",
    "GROUP BY s.seller_state, s.seller_city\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result6 = spark.sql(query6)\n",
    "display(result6)\n",
    "Business Question: \"Who are our top-performing sellers?\"\n",
    "\n",
    "Query 7: Customer Satisfaction Analysis\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 7: Review Score Distribution\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query7 = \"\"\"\n",
    "SELECT \n",
    "    f.review_score,\n",
    "    COUNT(f.sale_key) as number_of_reviews,\n",
    "    ROUND(COUNT(f.sale_key) * 100.0 / SUM(COUNT(f.sale_key)) OVER (), 2) as percentage\n",
    "FROM fact_sales f\n",
    "WHERE f.review_score > 0\n",
    "GROUP BY f.review_score\n",
    "ORDER BY f.review_score DESC\n",
    "\"\"\"\n",
    "\n",
    "result7 = spark.sql(query7)\n",
    "display(result7)\n",
    "Business Question: \"How satisfied are our customers?\"\n",
    "\n",
    "Query 8: Monthly Revenue Trend (2017-2018)\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 8: Monthly Revenue Trend\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query8 = \"\"\"\n",
    "SELECT \n",
    "    d.year,\n",
    "    d.month,\n",
    "    d.month_name,\n",
    "    COUNT(DISTINCT f.order_id) as orders,\n",
    "    ROUND(SUM(f.total_amount), 2) as revenue,\n",
    "    ROUND(AVG(f.total_amount), 2) as avg_order_value\n",
    "FROM fact_sales f\n",
    "JOIN dim_date d ON f.date_key = d.date_key\n",
    "WHERE d.year IN (2017, 2018)\n",
    "GROUP BY d.year, d.month, d.month_name\n",
    "ORDER BY d.year, d.month\n",
    "\"\"\"\n",
    "\n",
    "result8 = spark.sql(query8)\n",
    "display(result8)\n",
    "Business Question: \"What's our monthly revenue trend?\"\n",
    "\n",
    "Query 9: Payment Methods Analysis\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 9: Payment Installments Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query9 = \"\"\"\n",
    "SELECT \n",
    "    f.payment_installments,\n",
    "    COUNT(f.sale_key) as number_of_transactions,\n",
    "    ROUND(SUM(f.payment_value), 2) as total_payment_value,\n",
    "    ROUND(AVG(f.payment_value), 2) as avg_payment_value\n",
    "FROM fact_sales f\n",
    "WHERE f.payment_installments > 0\n",
    "GROUP BY f.payment_installments\n",
    "ORDER BY f.payment_installments\n",
    "\"\"\"\n",
    "\n",
    "result9 = spark.sql(query9)\n",
    "display(result9)\n",
    "Business Question: \"How do customers prefer to pay? (Installments)\"\n",
    "\n",
    "Query 10: Advanced - Customer Lifetime Value (CLV)\n",
    "pythonprint(\"=\" * 60)\n",
    "print(\"ðŸ“Š QUERY 10: Top 20 Customers by Lifetime Value\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query10 = \"\"\"\n",
    "SELECT \n",
    "    c.customer_key,\n",
    "    c.customer_city,\n",
    "    c.customer_state,\n",
    "    c.customer_segment,\n",
    "    COUNT(DISTINCT f.order_id) as total_orders,\n",
    "    COUNT(f.sale_key) as total_items_purchased,\n",
    "    ROUND(SUM(f.total_amount), 2) as lifetime_value,\n",
    "    ROUND(AVG(f.total_amount), 2) as avg_order_value,\n",
    "    ROUND(AVG(f.review_score), 2) as avg_satisfaction\n",
    "FROM fact_sales f\n",
    "JOIN dim_customer c ON f.customer_key = c.customer_key\n",
    "GROUP BY c.customer_key, c.customer_city, c.customer_state, c.customer_segment\n",
    "ORDER BY lifetime_value DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "result10 = spark.sql(query10)\n",
    "display(result10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ae4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
